# simple-crawler

Необходимо создать простой интернет crawler, который будет доставать из страниц информацию о названии сайта. Это должно быть приложение с http эндпоинтом. На этот эндпоинт поступает список http url'ов. Приложение должно пройтись по всем предоставленным урлам и достать оттуда название. Названием условно будем считать содержимое тэга title. После изъятия информации из всех страниц эндпоинт должен вернуть ответ, в котором каждому входному урлу соответствует найденное название. Все недостающие требования или неоднозначности начальной формулировки задачи вы должны разрешить самостоятельно - это является частью задания. Единственное требование к реализации - приложение должно быть написано на языке Scala.

# Реализация

- [http4s](https://github.com/http4s/http4s) - HTTP сервер
- [scala-scraper](https://github.com/ruippeixotog/scala-scraper) - загрузка страниц и парсинг тэга `<title>`
- [fs2](https://github.com/functional-streams-for-scala/fs2) - параллельный запуск нескольких парсеров

# Запуск

- собрать отдельное приложение через `sbt assembly`
- `sbt run` / `sbt reStart`

Параметры запуска можно посмотреть в файле [application.conf](src/main/resources/application.conf)

# Документация

[Openapi](src/main/resources/openapi.yml)

Сервер принимает запрос вида:

```json
{
  "urls": ["http://google.com"]
}
```

Возвращает ответ вида:

```json
{
  "titles": [
    {
      "url": "http://google.com",
      "title": "Google"
    }
  ],
  "errors": [
    {
      "url": "vk.com",
      "error": "Malformed URL: vk.com"
    }
  ]
}
```
`error` - ошибка, которую возвращает scala-scraper при неудачном парсинге
